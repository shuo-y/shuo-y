<!DOCTYPE html>
<html>
<head>
<meta name="robots" content="noindex">
<title>Shuo Yang</title>
<style type="text/css">

ul {
  list-style: none;
  margin-left: 0;
  padding-left: 0;
}

li {
  padding-bottom: 1em;
}

html {
  max-width: 60em;
  text-align:justify;
  font-family: sans-serif;
  padding-left: 1em;
  padding-right: 1em;
}
</style>
</head>
<body>

<h1>Shuo Yang</h1>

<p><a href="mailto:yang.5229@buckeyemail.osu.edu">yang.5229@buckeyemail.osu.edu</a></p>

<p>Hello! I am a PhD student in Computer Science and Engineering at The Ohio State University.
My research interests include machine learning and systems. I focus on the predict-then-optimize and tree-based methods recently.
</p>

<h2>Projects</h2>

<ul>
    <li> <b>Gradient boosting framework for predict-then-optimize framework</b>
    XGBoost or other gradient boosting frameworks show good performance for structured data which is used by many predict-then-optimize tasks. This project tries to answer: What kinds of predict-then-optimize tasks are more suitable for gradient boosting frameworks rather than neural network? How to come up with a method which can fill the gap between the tree-based methods and neural networks?
    </li>
    <li> <b>Improving the question answering system </b>
    In a text-to-SQL system,
    I investigated if using policy gradient methods can reduce the
    number of instructions from users and keep or improve the accuracy.
    In a question answering NLP task, I investigated if self-ensembling can enable model to answer questions which are not closely related to the given training data.
    <a href="https://gitlab.com/shuo-yang/nlphw">[Code 1]</a>
    <a href="https://drive.google.com/file/d/1ubhJwkikIU2yQy3H3alxqeHPoKLjSBHT/view?usp=sharing">[Report 1]</a>
    <a href="https://github.com/shuo-y/self-ensembling-qa">[Code 2]</a>
    <a href="https://drive.google.com/file/d/11ep2usRTcYX2lkrLJgius4NYiCbQhpUR/view?usp=sharing">[Report 2]</a>
    </li>
  <li><b>Reinforcement learning for ridesharing assistant</b>
    I investigated whether using RL algorithm can help ridersharing driver strategically accept new orders in order to maximize the overall revenue. The code and simulation of the driver's behaviors is based on a dataset from Gridwise.
    <a href="https://gitlab.com/shuo-yang/rl-course-project">[Code]</a>
    <a href="https://drive.google.com/file/d/1zDC-6atTnvUn0rNR1moYrQq2oxS9YUBa/view?usp=sharing">[Report]</a>
    </li>
</ul>



</body>
</html>
